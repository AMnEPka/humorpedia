#!/usr/bin/env python3
"""–ò–º–ø–æ—Ä—Ç –∫–æ–º–∞–Ω–¥ –ö–í–ù –∏–∑ humorbd.sql –≤ MongoDB.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∫–æ–º–∞–Ω–¥—ã –ö–í–ù (parent=1031), –∏–∑–≤–ª–µ–∫–∞—è:
- –¢–∞–±–ª–∏—Ü—É —Å —Ñ–∞–∫—Ç–∞–º–∏ (–ì–æ—Ä–æ–¥, –ì–æ–¥ –æ—Å–Ω–æ–≤–∞–Ω–∏—è, –ö–∞–ø–∏—Ç–∞–Ω, –í—ã—Å—à–∞—è –ª–∏–≥–∞, –ö–∏–í–∏–ù—ã –∏ —Ç.–¥.)
- –ù–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ (–°–æ—Å—Ç–∞–≤, –ò—Å—Ç–æ—Ä–∏—è, –∏ —Ç.–ø.)
- –¢–∞–π–º–ª–∞–π–Ω (–µ—Å–ª–∏ –µ—Å—Ç—å)
- –§–æ—Ç–æ, —Ä–µ–π—Ç–∏–Ω–≥–∏, —Ç–µ–≥–∏

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  # dry-run –¥–ª—è –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã
  python3 import_kvn_team.py --ids 1138 --dry-run
  
  # –∏–º–ø–æ—Ä—Ç –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã
  python3 import_kvn_team.py --ids 1138 --apply
  
  # –∏–º–ø–æ—Ä—Ç –ø–∞—á–∫–∏ –∏–∑ kvn_teams_list.json
  python3 import_kvn_team.py --from-list --limit 10 --apply
"""

from __future__ import annotations

import argparse
import json
import os
import re
import sys
from datetime import datetime, timezone
from uuid import uuid4

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pymongo
from import_people_from_sql import (
    _extract_for_ids,
    _load_image_map,
    _load_tv_map,
    _parse_migx,
    _timeline_from_migx_sections,
)
from utils import DB_NAME, MONGO_URL, normalize_rich_text

SQL_FILE = "/app/humorbd.sql"
KVN_TEAMS_LIST_FILE = "/app/migration/kvn/kvn_teams_list.json"
IMAGE_MAP_FILE = "/app/migration/image_mapping.json"
TAG_MAP_FILE = "/app/migration/tag_mapping.json"


# Transliteration map for cyrillic -> latin slugs (from backend/services/tags.py)
TRANSLIT_MAP = {
    '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
    '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
    '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
    '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
    '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya'
}


def transliterate_slug(text: str) -> str:
    """Convert cyrillic text to latin slug"""
    slug = text.lower().replace(" ", "-").replace(".", "").replace(",", "")
    slug = ''.join(TRANSLIT_MAP.get(char, char) for char in slug)
    # Remove non-alphanumeric characters except dashes
    slug = re.sub(r'[^a-z0-9-]', '', slug)
    # Remove consecutive dashes
    slug = re.sub(r'-+', '-', slug)
    return slug.strip('-')


def sync_tags_to_collection(tags: list[str], db) -> None:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è TagService.sync_tags().
    –°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–µ —Ç–µ–≥–∏ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ tags, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç.
    –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç usage_count –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö.
    """
    if not tags:
        return
    
    for tag_name in tags:
        tag_name = tag_name.strip()
        if not tag_name:
            continue
        
        # Check if tag already exists (case-insensitive)
        existing = db.tags.find_one({
            "name": {"$regex": f"^{re.escape(tag_name)}$", "$options": "i"}
        })
        
        if not existing:
            # Create new tag
            tag_doc = {
                "_id": str(uuid4()),
                "name": tag_name,
                "slug": transliterate_slug(tag_name),
                "old_id": None,
                "usage_count": 1,
                "created_at": datetime.now(timezone.utc).isoformat()
            }
            try:
                db.tags.insert_one(tag_doc)
                print(f"  ‚úÖ Created tag: {tag_name}")
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Failed to create tag {tag_name}: {e}")
        else:
            # Increment usage count
            db.tags.update_one(
                {"_id": existing["_id"]},
                {"$inc": {"usage_count": 1}}
            )


def _load_tag_map():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ tag_id -> tag_name –∏–∑ JSON —Ñ–∞–π–ª–∞."""
    if not os.path.exists(TAG_MAP_FILE):
        print(f"‚ö†Ô∏è  Tag mapping file not found: {TAG_MAP_FILE}")
        return {}
    
    with open(TAG_MAP_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)


def _tags_from_tv(tv_tags_str: str, tag_map: dict) -> list[str]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É TV 'tags' –≤ —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–µ–≥–æ–≤."""
    if not tv_tags_str:
        return []
    
    tag_ids = tv_tags_str.split('||')
    tag_names = []
    
    for tag_id in tag_ids:
        tag_id = tag_id.strip()
        if tag_id in tag_map:
            tag_names.append(tag_map[tag_id])
    
    return tag_names


def create_team_document(
    title: str,
    slug: str,
    name: str = None,
    logo_url: str = None,
    facts: dict = None,
    text_blocks: list[dict] = None,
    timeline_events: list[dict] = None,
    tags: list[str] = None,
    rating: dict = None,
    social_links: dict = None,
):
    """–°–æ–∑–¥–∞—ë—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∫–æ–º–∞–Ω–¥—ã –¥–ª—è MongoDB."""
    modules = []
    order = 1

    # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫ - –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç (–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞)
    if text_blocks and len(text_blocks) > 0 and not text_blocks[0].get('title'):
        modules.append({
            'id': str(uuid4()),
            'type': 'text_block',
            'order': order,
            'title': '',
            'visible': True,
            'data': {
                'title': '',
                'content': normalize_rich_text(text_blocks[0]['content']),
            }
        })
        order += 1
        text_blocks = text_blocks[1:]  # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π –±–ª–æ–∫ –∏–∑ —Å–ø–∏—Å–∫–∞

    # –¢–∞–π–º–ª–∞–π–Ω –∏–¥—ë—Ç –≤—Ç–æ—Ä—ã–º
    if timeline_events:
        normalized_events = []
        for ev in timeline_events:
            if not isinstance(ev, dict):
                continue
            normalized_events.append({
                'year': normalize_rich_text(str(ev.get('year', ''))) if ev.get('year') else None,
                'title': normalize_rich_text(str(ev.get('title', ''))) if ev.get('title') else None,
                'description': normalize_rich_text(str(ev.get('description', ''))) if ev.get('description') else None,
            })

        if normalized_events:
            modules.append({
                'id': str(uuid4()),
                'type': 'timeline',
                'order': order,
                'title': '–•—Ä–æ–Ω–æ–ª–æ–≥–∏—è',
                'visible': True,
                'data': {
                    'title': '–•—Ä–æ–Ω–æ–ª–æ–≥–∏—è',
                    'items': normalized_events,
                }
            })
            order += 1

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ (4 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö)
    if text_blocks:
        for block in text_blocks:
            if block.get('content'):
                modules.append({
                    'id': str(uuid4()),
                    'type': 'text_block',
                    'order': order,
                    'title': block.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'),
                    'visible': True,
                    'data': {
                        'title': block.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'),
                        'content': normalize_rich_text(block['content']),
                    }
                })
                order += 1

    return {
        '_id': str(uuid4()),
        'content_type': 'team',
        'team_type': 'kvn',
        'title': title,
        'slug': slug,
        'name': name or title,
        'status': 'published',
        'tags': tags or [],
        'created_at': datetime.now(timezone.utc).isoformat(),
        'updated_at': datetime.now(timezone.utc).isoformat(),
        'facts': facts or {},
        'social_links': social_links or {},
        'modules': modules,
        'rating': rating or {'average': 0.0, 'count': 0},
        'votes_count': rating.get('count', 0) if rating else 0,
        'views': 0,
        'member_ids': [],
        'show_ids': [],
        'featured': False,
        'logo': logo_url,
        'seo': {
            'meta_title': title,
            'meta_description': '',
        }
    }


def _parse_facts_table(table_html: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∞–∫—Ç—ã –∏–∑ HTML-—Ç–∞–±–ª–∏—Ü—ã."""
    if not table_html:
        return {}

    import re
    facts = {}
    
    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã <tr><td>Key</td><td>Value</td></tr>
    rows = re.findall(r'<tr>\s*<td>(.*?)</td>\s*<td>(.*?)</td>\s*</tr>', table_html, re.IGNORECASE | re.DOTALL)
    
    for key_html, val_html in rows:
        # –£–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏
        key = re.sub(r'<[^>]+>', '', key_html).strip()
        val = normalize_rich_text(val_html)
        
        if key and val:
            facts[key] = val
    
    return facts


def build_team_doc(sc, tv_by_id: dict[str, str], tv_map: dict[str, str], image_map: dict[str, str], tag_map: dict[str, str]):
    """–°—Ç—Ä–æ–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∫–æ–º–∞–Ω–¥—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö SQL."""
    tv_named = {}
    for tv_id, val in tv_by_id.items():
        tv_name = tv_map.get(tv_id)
        if tv_name:
            tv_named[tv_name] = val

    # Parse MIGX
    sections = _parse_migx(tv_named.get("config", ""))

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ñ–∞–∫—Ç–æ–≤ –∏–∑ —Å–µ–∫—Ü–∏–∏ "info"
    facts = {}
    main_content = ""
    for sec in sections:
        if sec.get("MIGX_formname") == "info":
            table_html = sec.get("table", "")
            facts = _parse_facts_table(table_html)
            # subtitle –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –æ –∫–æ–º–∞–Ω–¥–µ
            main_content = sec.get("subtitle", "")
            break

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏
    all_text_sections = []
    for sec in sections:
        if sec.get("MIGX_formname") == "text":
            title = sec.get("section_name", "")
            # –ö–æ–Ω—Ç–µ–Ω—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ 'content' –∏–ª–∏ 'subtitle'
            content = sec.get("content", "") or sec.get("subtitle", "")
            if content:
                all_text_sections.append({
                    'title': title,
                    'content': content,
                })
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –∏–≥—Ä
    games_table_html = ""
    for sec in sections:
        if sec.get("MIGX_formname") == "table":
            games_table_html = sec.get("content", "")
            break
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ 4 –±–ª–æ–∫–∞ –¥–ª—è –∫–æ–º–∞–Ω–¥ –ö–í–ù
    text_blocks = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç –∫–∞–∫ –ø–µ—Ä–≤—ã–π –±–ª–æ–∫ (–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞)
    if main_content:
        text_blocks.append({
            'title': '',
            'content': main_content,
        })
    
    # 1. –°–æ—Å—Ç–∞–≤ –∫–æ–º–∞–Ω–¥—ã –ö–í–ù
    sostav = None
    for block in all_text_sections:
        if '–°–æ—Å—Ç–∞–≤' in block['title']:
            sostav = block
            break
    if sostav:
        text_blocks.append(sostav)
    
    # 2. –ò—Å—Ç–æ—Ä–∏—è –∫–æ–º–∞–Ω–¥—ã - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –±–ª–æ–∫–∏ —Å "–ò—Å—Ç–æ—Ä–∏—è"
    history_blocks = [b for b in all_text_sections if '–ò—Å—Ç–æ—Ä–∏—è' in b['title']]
    if history_blocks:
        combined_history = '\n\n'.join([b['content'] for b in history_blocks])
        text_blocks.append({
            'title': '–ò—Å—Ç–æ—Ä–∏—è –∫–æ–º–∞–Ω–¥—ã',
            'content': combined_history,
        })
    
    # 3. –°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç—ã
    projects = None
    for block in all_text_sections:
        if '–°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç—ã' in block['title']:
            projects = block
            break
    if projects:
        text_blocks.append({
            'title': '–°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç—ã –∫–æ–º–∞–Ω–¥—ã –ø–æ—Å–ª–µ/–≤–æ –≤—Ä–µ–º—è –∏–≥—Ä—ã –≤ –ö–í–ù',
            'content': projects['content'],
        })
    
    # 4. –°–ø–∏—Å–æ–∫ –∏–≥—Ä –∫–æ–º–∞–Ω–¥—ã (–ª–µ–≥–µ–Ω–¥–∞ + —Ç–∞–±–ª–∏—Ü–∞)
    games = None
    for block in all_text_sections:
        if '–°–ø–∏—Å–æ–∫ –∏–≥—Ä' in block['title']:
            games = block
            break
    if games:
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É –∏ —Ç–∞–±–ª–∏—Ü—É
        games_content = games['content']
        if games_table_html:
            games_content = games_content + "\n\n" + games_table_html
        
        text_blocks.append({
            'title': '–°–ø–∏—Å–æ–∫ –∏–≥—Ä –∫–æ–º–∞–Ω–¥—ã',
            'content': games_content,
        })

    # –¢–∞–π–º–ª–∞–π–Ω
    timeline_events = _timeline_from_migx_sections(sections)

    # Tags - –∏–∑ TV –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    tags = _tags_from_tv(tv_named.get('tags', ''), tag_map)

    # Rating
    avg = float(sc.rating or 0.0)
    if avg < 0:
        avg = 0.0
    if avg > 10:
        avg = 10.0
    rating = {"average": avg, "count": int(sc.votes or 0)}

    # Image - –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å /media/imported/
    image_url = None
    tv_img = tv_named.get('img')
    if tv_img:
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å /media/imported/ –µ—Å–ª–∏ –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π
        if not str(tv_img).startswith('/'):
            image_url = f"/media/imported/{str(tv_img).lstrip('/')}"
        else:
            image_url = tv_img

    # Social links - –¥–æ–±–∞–≤–ª—è–µ–º –≤–µ–±-—Å–∞–π—Ç –¥–ª—è –£—Ä–∞–ª—å—Å–∫–∏—Ö –ø–µ–ª—å–º–µ–Ω–µ–π
    social_links = {}
    if sc.alias == 'uralskie-pelmeni':
        social_links['website'] = 'https://pelmeny.net/'

    doc = create_team_document(
        title=sc.pagetitle,
        slug=sc.alias,
        name=sc.longtitle or sc.pagetitle,
        logo_url=image_url,
        facts=facts,
        text_blocks=text_blocks,
        timeline_events=timeline_events,
        tags=tags,
        rating=rating,
        social_links=social_links,
    )

    return doc


def main():
    parser = argparse.ArgumentParser(description="–ò–º–ø–æ—Ä—Ç –∫–æ–º–∞–Ω–¥ –ö–í–ù –∏–∑ SQL –≤ MongoDB")
    parser.add_argument("--ids", nargs="+", type=int, help="–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ ID –∫–æ–º–∞–Ω–¥ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞")
    parser.add_argument("--from-list", action="store_true", help="–ò–º–ø–æ—Ä—Ç –∏–∑ kvn_teams_list.json")
    parser.add_argument("--limit", type=int, default=1, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–∞–Ω–¥ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –∏–∑ —Å–ø–∏—Å–∫–∞")
    parser.add_argument("--dry-run", action="store_true", help="–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å, –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å")
    parser.add_argument("--apply", action="store_true", help="–ü—Ä–∏–º–µ–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è")
    args = parser.parse_args()

    if not args.dry_run and not args.apply:
        print("–£–∫–∞–∂–∏—Ç–µ --dry-run –∏–ª–∏ --apply")
        return

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ ID –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
    if args.ids:
        target_ids = set(args.ids)
    elif args.from_list:
        if not os.path.exists(KVN_TEAMS_LIST_FILE):
            print(f"–§–∞–π–ª {KVN_TEAMS_LIST_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ build_kvn_teams_list.py")
            return
        
        with open(KVN_TEAMS_LIST_FILE, "r", encoding="utf-8") as f:
            teams_list = json.load(f)
        
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ pending
        pending = [t for t in teams_list if t.get("status") == "pending"]
        target_ids = set([t["id"] for t in pending[:args.limit]])
        
        if not target_ids:
            print("–ù–µ—Ç pending –∫–æ–º–∞–Ω–¥ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞")
            return
    else:
        print("–£–∫–∞–∂–∏—Ç–µ --ids –∏–ª–∏ --from-list")
        return

    print(f"–ò–º–ø–æ—Ä—Ç {len(target_ids)} –∫–æ–º–∞–Ω–¥: {sorted(target_ids)}\n")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    tv_map = _load_tv_map()
    image_map = _load_image_map()
    tag_map = _load_tag_map()
    site_content, tv_values = _extract_for_ids(target_ids)

    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB
    client = None
    collection = None
    if args.apply:
        client = pymongo.MongoClient(MONGO_URL)
        db = client[DB_NAME]
        collection = db["teams"]  # Store teams in 'teams' collection

    imported_count = 0
    
    for team_id in sorted(target_ids):
        sc = site_content.get(team_id)
        if not sc:
            print(f"‚ö†Ô∏è  ID {team_id}: –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ SQL")
            continue

        tv_by_id = tv_values.get(team_id, {})
        
        try:
            doc = build_team_doc(sc, tv_by_id, tv_map, image_map, tag_map)
            
            print(f"\n{'='*60}")
            print(f"ID {team_id}: {doc['title']} ({doc['slug']})")
            print(f"{'='*60}")
            print(f"Facts: {len(doc['facts'])} items")
            for k, v in doc['facts'].items():
                print(f"  - {k}: {v[:60]}")
            print(f"Text blocks: {len([m for m in doc['modules'] if m['type'] == 'text_block'])}")
            for m in doc['modules']:
                if m['type'] == 'text_block':
                    print(f"  - {m['title'] or '(–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞)'}: {len(m['data']['content'])} chars")
            
            timeline_count = len([m for m in doc['modules'] if m['type'] == 'timeline'])
            if timeline_count:
                timeline = [m for m in doc['modules'] if m['type'] == 'timeline'][0]
                print(f"Timeline: {len(timeline['data']['items'])} events")
            
            print(f"Tags: {doc['tags']}")
            print(f"Rating: {doc['rating']['average']} ({doc['rating']['count']} votes)")
            print(f"Logo: {doc['logo']}")

            if args.apply:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ
                existing = collection.find_one({"slug": doc['slug'], "content_type": "team"})
                if existing:
                    print(f"‚ö†Ô∏è  –ö–æ–º–∞–Ω–¥–∞ —Å slug '{doc['slug']}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue
                
                # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Ç–µ–≥–∏ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é tags
                if doc['tags']:
                    print(f"  üìå Syncing {len(doc['tags'])} tags...")
                    sync_tags_to_collection(doc['tags'], db)
                
                collection.insert_one(doc)
                imported_count += 1
                print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ —Å–ø–∏—Å–∫–µ
                if args.from_list:
                    for t in teams_list:
                        if t["id"] == team_id:
                            t["status"] = "imported"
                    with open(KVN_TEAMS_LIST_FILE, "w", encoding="utf-8") as f:
                        json.dump(teams_list, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ ID {team_id}: {e}")
            import traceback
            traceback.print_exc()

    if client:
        client.close()

    print(f"\n{'='*60}")
    print(f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {imported_count} –∏–∑ {len(target_ids)}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
